{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This guide trains a neural network model to classify images of clothing.\n",
    "\n",
    "    Uses tf.keras   ->      a high-level API to build and train models in TF.\n",
    "\n",
    "    https://www.tensorflow.org/tutorials/keras/classification\n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "#   TensorFlow & Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#   Helper Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Import the Fashion MNIST dataset\n",
    "                                    -> 70,000 grayscale images in 10 categories\n",
    "                                    -> 28 x 28 pixels\n",
    "\n",
    "    intended as a replacement for the classic MNIST dataset\n",
    "\n",
    "    60,000 images   ->  train the network\n",
    "    10,000 images   ->  eval accuracy\n",
    "'''\n",
    "\n",
    "#   Import & Load dataset directly from TensorFlow\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "'''\n",
    "    load_data() returns ->  Tuple of 4 NumPy arrays\n",
    "                                (x_train, y_train), (x_test,y_test)\n",
    "                            ie\n",
    "                                (train_images, train_labels), (test_images, test_labels) \n",
    "                            https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data\n",
    "\n",
    "    \n",
    "    Each image is mapped to a single label.\n",
    "    Since the class names are not included with the dataset,\n",
    "    store them here to use later when plotting the image:\n",
    "\n",
    "'''\n",
    "class_names = ['T-shirt/top', 'Trousers', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#   Explore the data\n",
    "'''\n",
    "#   Returns shape of the array in a tuple, ie (60,000, 28, 28)\n",
    "print(train_images.shape)\n",
    "'''\n",
    "train_images as well as the other 3 items returned from load_data() during the previous step\n",
    "are in fact of type\n",
    "\n",
    "    numpy.ndarray\n",
    "\n",
    "\n",
    "So they comply to:  https://numpy.org/devdocs/reference/generated/numpy.ndarray.shape.html#numpy.ndarray.shape\n",
    "                    https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html\n",
    "\n",
    "->  Nice Link:      https://note.nkmk.me/en/python-numpy-ndarray-ndim-shape-size/\n",
    "\n",
    "    \"The shape (= size of each dimension) of numpy.ndarray can be obtained as a tuple with attribute shape.\n",
    "\n",
    "        Even in the case of a one-dimensional array, it is a tuple with one element instead of an integer value.\n",
    "        Note that a tuple with one element has a trailing comma.\"\n",
    "\n",
    "\n",
    "At first i got confused by tf.shape     https://www.tensorflow.org/api_docs/python/tf/shape\n",
    "and went to\n",
    "                                        https://www.tensorflow.org/api_docs/python/tf/Tensor#consumers\n",
    "            which states that tensor.consumers() returns a list of Operations that consume this tensor.\n",
    "\n",
    "            attempting to return the consumers list resulted in the following error:\n",
    "                ---------------------------------------------------------------------------\n",
    "                AttributeError                            Traceback (most recent call last)\n",
    "                in \n",
    "                    32 \n",
    "                    33 #type(train_images)\n",
    "                ---> 34 train_images.consumers()\n",
    "\n",
    "                AttributeError: 'numpy.ndarray' object has no attribute 'consumers'\n",
    "                ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "However, a more solid approach to test object types, is to use\n",
    "\n",
    "    type(object)    ->  Which here returns numpy.ndarray\n",
    "\n",
    "\n",
    "    could just do       type(train_images)              =>      numpy.ndarray\n",
    "    or even             print(type(train_images))       =>      <class 'numpy.ndarray'>\n",
    "'''\n",
    "\n",
    "#   Number of Training Images   ie  60000\n",
    "print(len(train_images))\n",
    "#   Number of Training Labels   ie  60000\n",
    "print(len(train_labels))\n",
    "\n",
    "#   Show numpy.ndarray structure    ie      array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)\n",
    "train_labels\n",
    "\n",
    "#   Returns shape of the array in a tuple, ie (10000, 28, 28)\n",
    "print(test_images.shape)\n",
    "\n",
    "#   Number of Testing Images    ie  10000\n",
    "print(len(test_images))\n",
    "\n",
    "#   Number of Testing Labels    ie  10000\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#   Preprocess the Data\n",
    "'''\n",
    "#   Inspecting the first image in the training set.\n",
    "#   Pixel values fall in the range of 0 to 255\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   We are going to scale images of both training as well as testing sets down to a scale in the range of 0 to 1\n",
    "#   Pixels are values between   ->  0 and 255\n",
    "#   We are effectively scaling down to  ->  0 and 255\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   To verify that our data in the correct format, let's display the first 25 images from both sets\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks()    #   label and item position on x-axis\n",
    "    plt.yticks()    #   label and item position on y-axis\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Build the Model\n",
    "\n",
    "\n",
    "Steps:\n",
    "#   Building the layers\n",
    "#   Compiling the model\n",
    "\n",
    "\n",
    "\n",
    "Most layers, such as tf.keras.layers.Dense -> params that are learned during training\n",
    "\n",
    "Here we used\n",
    "        1 layer which flattens the pixels (from a 2-dimensional array => 1-dimensional)\n",
    "        &\n",
    "        2 learning layers\n",
    "\n",
    "Layer Documentation can be found in:\n",
    "        - Flattening Layer: Flattens the input. Does not affect the batch size.\n",
    "        https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten\n",
    "\n",
    "        - Just your regular densely-connected NN layer.\n",
    "        https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "            tf.keras.layers.Dense(\n",
    "                units, activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None,\n",
    "                activity_regularizer=None, kernel_constraint=None, bias_constraint=None,\n",
    "                **kwargs\n",
    "            )\n",
    "            Dense implements the operation: output = activation(dot(input, kernel) + bias)\n",
    "            where activation is the element-wise activation function passed as the activation argument,\n",
    "            kernel is a weights matrix created by the layer,\n",
    "            and bias is a bias vector created by the layer (only applicable if use_bias is True).\n",
    "\n",
    "keras.Sequential\n",
    "        https://keras.io/models/sequential/\n",
    "        keras.Sequential.compile\n",
    "                        .fit\n",
    "                        .train\n",
    "                        .get_layer\n",
    "                        .train_on_batch\n",
    "                        ..\n",
    "\n",
    "type(model)\n",
    "tensorflow.python.keras.engine.sequential.Sequential\n",
    "'''\n",
    "\n",
    "#   Set the layers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),     #   Layer 1:\n",
    "                                                    #       transforms image format -   No Learning\n",
    "                                                    #       from a two-dimentional array (28 x 28)\n",
    "                                                    #       to\n",
    "                                                    #       one-dimensional array of    28 * 28 = 784 pixels\n",
    "    keras.layers.Dense(128, activation='relu'),     #   Layer 2:\n",
    "                                                    #       Densely Connected Neural Layers\n",
    "                                                    #       128 Neurons\n",
    "                                                    #       relu Activation Function\n",
    "    keras.layers.Dense(10)                          #   Layer 3:\n",
    "                                                    #       Returns a logits array with length of 10\n",
    "                                                    #       Each node contains a score that\n",
    "                                                    #       indicates the current image belongs to one of the 10 classes\n",
    "])\n",
    "\n",
    "\n",
    "#   Compile the Model\n",
    "\n",
    "'''\n",
    "Before training, during compilation, the model needs a few settings:\n",
    "\n",
    "- Loss function - Measures accuracy during training.\n",
    "                    We need to minimize this function - Effectively steering the model in the right direction\n",
    "- Optimizer - How the model is updated\n",
    "                based on the data it sees and its loss function\n",
    "- Metrics - Monitor training & testing\n",
    "                This example uses accuracy, the fraction of the images that are correctly classified\n",
    "'''\n",
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train the model\n",
    "\n",
    "\n",
    "Steps:\n",
    "    1) Feed training data to model  -   train_images \n",
    "                                    -   train_labels\n",
    "\n",
    "    2) Model learns to associate        [  images  ]   -   [   labels  ]\n",
    "\n",
    "    3) Ask the model to make predictions on test data   -   test_images\n",
    "\n",
    "    4) Verify that the predictions match the labels     -   test_labels\n",
    "\n",
    "Remember\n",
    "model is of type:   tensorflow.python.keras.engine.sequential.Sequential\n",
    "'''\n",
    "\n",
    "#   Feed Model\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "#   Evaluate Accuracy\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy:', test_acc)\n",
    "\n",
    "'''\n",
    "-----------------------------------------------------------------------------------------------\n",
    "Train on 60000 samples\n",
    "Epoch 1/10\n",
    "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4992 - accuracy: 0.8255\n",
    "Epoch 2/10\n",
    "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3750 - accuracy: 0.8653\n",
    "Epoch 3/10\n",
    "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3385 - accuracy: 0.8766\n",
    "Epoch 4/10\n",
    "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3152 - accuracy: 0.8846\n",
    "Epoch 5/10\n",
    "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2959 - accuracy: 0.8906\n",
    "Epoch 6/10\n",
    "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2830 - accuracy: 0.8945\n",
    "Epoch 7/10\n",
    "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2699 - accuracy: 0.8991\n",
    "Epoch 8/10\n",
    "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2576 - accuracy: 0.9044\n",
    "Epoch 9/10\n",
    "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2485 - accuracy: 0.9082\n",
    "Epoch 10/10\n",
    "60000/60000 [==============================] - 3s 51us/sample - loss: 0.2379 - accuracy: 0.9124\n",
    "10000/10000 - 0s - loss: 0.3487 - accuracy: 0.8783\n",
    "\n",
    "Test Accuracy: 0.8783\n",
    "-----------------------------------------------------------------------------------------------\n",
    "\n",
    "During training - peak accuracy -> 0.91 ie 91%\n",
    "During testing -> 87%\n",
    "\n",
    "\n",
    "Turns out that the accuracy on the test dataset is a little less than that of the training set.\n",
    "\n",
    "This gap between training accuracy & test accuracy represents overfitting.\n",
    "\n",
    "=>\n",
    "Overfitting happens when a machine learning model performs worse on new,\n",
    "previously unseen input.\n",
    "\n",
    "An overfitted model \"memorizes\" the noise and details in the training dataset to a point where\n",
    "it negatively impacts the performance of the model on the new data.\n",
    "\n",
    "    overfitting:\n",
    "        https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#demonstrate_overfitting\n",
    "    strategies to prevent overfitting:\n",
    "        https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make Predictions\n",
    "\n",
    "\n",
    "The model's linear outputs => logits.\n",
    "Logits:         https://developers.google.com/machine-learning/glossary#logits\n",
    "    The vector of raw (non-normalized) predictions that a classification model generates,\n",
    "    which is ordinarily then passed to a normalization function.\n",
    "    \n",
    "    If the model is solving a multi-class classification problem,\n",
    "    logits typically become an input to the softmax function.\n",
    "\n",
    "    The softmax function then generates a vector of (normalized) probabilities with one value for each possible class.\n",
    "\n",
    "    In addition, logits sometimes refer to the element-wise inverse of the sigmoid function.\n",
    "\n",
    "'''\n",
    "\n",
    "#   Attach a softmax layer => Convert the Logits to probabilities\n",
    "probability_model = tf.keras.Sequential([model,\n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "#   Predict         ie  a label for each image in the testing set\n",
    "predictions = probability_model.predict(test_images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#   Check the 1st prediction\n",
    "print(predictions[0],'\\n')\n",
    "'''\n",
    "array([4.1863575e-11, 3.5028733e-11, 3.9013325e-15, 2.2995087e-17,\n",
    "       8.3599377e-11, 6.1338292e-06, 5.7371097e-11, 1.9842522e-04,\n",
    "       2.2990771e-11, 9.9979550e-01], dtype=float32)\n",
    "\n",
    "\n",
    "So, our prediction is an array of 10 numbers.\n",
    "These numbers represent confidence that this image belongs to each label.\n",
    "\n",
    "\n",
    "If we pick the max => The label predicted\n",
    "'''\n",
    "\n",
    "print('1st Prediction - Category:', np.argmax(predictions[0]),\n",
    "        'the actual Category - Label:', test_labels[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#   Graph Predictions, to view the full set of 10 class predictions\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    #   Cast params into local vars\n",
    "    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                            100*np.max(predictions_array),\n",
    "                                            class_names[true_label]),\n",
    "                                            color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    #   Cast params into local vars\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color='#777777')\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "#   Verify Predictions\n",
    "\n",
    "#   Correct ->  blue\n",
    "#   Incorrect   ->  red\n",
    "#   Number -> % for the predicted label\n",
    "\n",
    "\n",
    "#   Look at 0th Image\n",
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i], test_labels)\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "\n",
    "#   Look at 12th Image\n",
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()\n",
    "\n",
    "#   Plot the first X test images, their predicted labels and true labels.\n",
    "#   Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions[i], test_labels, test_images)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use the trained model to make a prediction about a single image\n",
    "\n",
    "\n",
    "tf.keras models are optimized to make predictions on a batch, or collection, of examples at once.\n",
    "                https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict\n",
    "\n",
    "Even though we want to use a single image we have to add it to a list\n",
    "\n",
    "\n",
    "\n",
    "predict(\n",
    "    x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,\n",
    "    workers=1, use_multiprocessing=False\n",
    ")\n",
    "Generates output predictions for the input samples.\n",
    "Computation is done in batches.\n",
    "Returns:    Numpy array(s) of predictions\n",
    "            ie\n",
    "            a list of lists - one list for each image in the batch of data.\n",
    "'''\n",
    "\n",
    "#   Grab img from the dataset\n",
    "img = test_images[1]\n",
    "\n",
    "print(img.shape)\n",
    "#   (28, 28)\n",
    "\n",
    "\n",
    "#   Add an image to a batch where it's the only member\n",
    "img = (np.expand_dims(img, 0))\n",
    "\n",
    "print(img.shape)\n",
    "#   (1, 28, 28)\n",
    "\n",
    "\n",
    "\n",
    "#   Predict\n",
    "predictions_single = probability_model.predict(img)\n",
    "\n",
    "print(predictions_single)\n",
    "#   [[1.36638206e-04 1.00125544e-20 9.99632239e-01 1.82900678e-12\n",
    "#   2.23441632e-04 1.49841226e-22 7.61113051e-06 4.43834729e-23\n",
    "#   4.28886663e-15 1.10596339e-17]]\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "plot_value_array(1, predictions_single[0], test_labels)\n",
    "_ = plt.xticks(range(10), class_names, rotation=45)\n",
    "\n",
    "\n",
    "sprediction = np.argmax(predictions_single[0])\n",
    "print('Prediction for this image:\\t', sprediction,'\\t', class_names[sprediction])"
   ]
  }
 ]
}